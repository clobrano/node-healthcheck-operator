apiVersion: operators.coreos.com/v1alpha1
kind: ClusterServiceVersion
metadata:
  annotations:
    alm-examples: |-
      [
        {
          "apiVersion": "remediation.medik8s.io/v1alpha1",
          "kind": "NodeHealthCheck",
          "metadata": {
            "name": "nodehealthcheck-sample"
          },
          "spec": {
            "minHealthy": "51%",
            "remediationTemplate": {
              "apiVersion": "self-node-remediation.medik8s.io/v1alpha1",
              "kind": "SelfNodeRemediationTemplate",
              "name": "self-node-remediation-resource-deletion-template",
              "namespace": "openshift-operators"
            },
            "selector": {
              "matchExpressions": [
                {
                  "key": "node-role.kubernetes.io/worker",
                  "operator": "Exists"
                }
              ]
            },
            "unhealthyConditions": [
              {
                "duration": "300s",
                "status": "False",
                "type": "Ready"
              },
              {
                "duration": "300s",
                "status": "Unknown",
                "type": "Ready"
              }
            ]
          }
        }
      ]
    capabilities: Basic Install
    categories: OpenShift Optional
    console.openshift.io/plugins: '["node-remediation-console-plugin"]'
    containerImage: quay.io/medik8s/node-healthcheck-operator:v0.0.1
    createdAt: ""
    description: Detect failed Nodes and trigger remediation with e.g. Self Node Remediation.
    olm.skipRange: '>=0.0.1'
    operators.operatorframework.io/builder: operator-sdk-v1.26.1
    operators.operatorframework.io/project_layout: go.kubebuilder.io/v3
    repository: https://github.com/medik8s/node-healthcheck-operator
    support: Medik8s
  name: node-healthcheck-operator.v0.0.1
  namespace: placeholder
spec:
  apiservicedefinitions: {}
  customresourcedefinitions:
    owned:
    - description: NodeHealthCheck is the Schema for the nodehealthchecks API
      displayName: Node Health Check
      kind: NodeHealthCheck
      name: nodehealthchecks.remediation.medik8s.io
      resources:
      - kind: NodeHealthCheck
        name: nodehealthchecks
        version: v1alpha1
      specDescriptors:
      - description: Remediation is allowed if at least "MinHealthy" nodes selected
          by "selector" are healthy. Expects either a positive integer value or a
          percentage value. Percentage values must be positive whole numbers and are
          capped at 100%. 100% is valid and will block all remediation.
        displayName: Min Healthy
        path: minHealthy
      - description: 'PauseRequests will prevent any new remdiation to start, while
          in-flight remediations keep running. Each entry is free form, and ideally
          represents the requested party reason for this pausing - i.e: "imaginary-cluster-upgrade-manager-operator"'
        displayName: Pause Requests
        path: pauseRequests
      - description: "RemediationTemplate is a reference to a remediation template
          provided by an infrastructure provider. \n If a node needs remediation the
          controller will create an object from this template and then it should be
          picked up by a remediation provider."
        displayName: Remediation Template
        path: remediationTemplate
      - description: 'Label selector to match nodes whose health will be exercised.
          Note: An empty selector will match all nodes.'
        displayName: Selector
        path: selector
      - description: UnhealthyConditions contains a list of the conditions that determine
          whether a node is considered unhealthy.  The conditions are combined in
          a logical OR, i.e. if any of the conditions is met, the node is unhealthy.
        displayName: Unhealthy Conditions
        path: unhealthyConditions
      statusDescriptors:
      - description: 'Represents the observations of a NodeHealthCheck''s current
          state. Known .status.conditions.type are: "Disabled"'
        displayName: conditions
        path: conditions
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:conditions
      - description: HealthyNodes specified the number of healthy nodes observed
        displayName: healthynodes
        path: healthyNodes
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:healthyNodes
      - description: InFlightRemediations records the timestamp when remediation triggered
          per node
        displayName: inFlightRemediations
        path: inFlightRemediations
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:inFlightRemediations
      - description: ObservedNodes specified the number of nodes observed by using
          the NHC spec.selector
        displayName: observedNodes
        path: observedNodes
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:observedNodes
      - description: Phase represents the current phase of this Config. Known phases
          are Disabled, Paused, Remediating and Enabled, based on:\n - the status
          of the Disabled condition\n - the value of PauseRequests\n - the value of
          InFlightRemediations
        displayName: phase
        path: phase
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:text
      - description: Reason explains the current phase in more detail.
        displayName: reason
        path: reason
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:text
      version: v1alpha1
  description: |
    ### Introduction
    Hardware is imperfect, and software contains bugs. When node level failures such as kernel hangs or dead NICs
    occur, the work required from the cluster does not decrease - workloads from affected nodes need to be
    restarted somewhere.

    However some workloads, such as RWO volumes and StatefulSets, may require at-most-one semantics.
    Failures affecting these kind of workloads risk data loss and/or corruption if nodes (and the workloads
    running on them) are assumed to be dead whenever we stop hearing from them. For this reason it is important
    to know that the node has reached a safe state before initiating recovery of the workload.

    Unfortunately it is not always practical to require admin intervention in order to confirm the node’s true status.
    In order to automate the recovery of exclusive workloads, we provide operators for failure detection
    and remediation.

    ### Failure detection: Node Health Check operator
    The “Node Health Check” (NHC) operator checks each Node’s set of
    NodeConditions (eg. NotReady) against the criteria and thresholds defined in
    NodeHealthCheck configuration. If the Node is deemed to be in a failed
    state, NHC will initiate recovery by using the SIG Cluster API's “External
    Remediation” API to instantiate the configured remediation template which
    specifies the mechanism/controller to be used.

    ### Failure handling: Self Node Remediation
    By default NHC depends on the “Self Node Remediation” (SNR) operator, which
    is installed automatically.
    SNR uses watchdog timers and heuristics to ensure nodes enter a safe state
    (no longer hosting workloads) within a known and finite period of time,
    before signaling to the system that all Pods and VolumeAttachments on the
    failed Node are no longer active and can be relocated elsewhere.
    In the case of transient errors, the watchdog’s actions will also result in
    the node rebooting and rejoining the cluster - restoring capacity.
  displayName: Node Health Check Operator
  icon:
  - base64data: base64EncodedIcon
    mediatype: image/png
  install:
    spec:
      clusterPermissions:
      - rules:
        - apiGroups:
          - apps
          resources:
          - deployments
          verbs:
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - config.openshift.io
          resources:
          - clusterversions
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - console.openshift.io
          resources:
          - consoleplugins
          verbs:
          - create
          - delete
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          resources:
          - nodes
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          resources:
          - services
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - machine.openshift.io
          resources:
          - machinehealthchecks
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - rbac.authorization.k8s.io
          resources:
          - clusterrolebindings
          verbs:
          - '*'
        - apiGroups:
          - rbac.authorization.k8s.io
          resources:
          - clusterroles
          verbs:
          - '*'
        - apiGroups:
          - remediation.medik8s.io
          resources:
          - nodehealthchecks
          verbs:
          - create
          - delete
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - remediation.medik8s.io
          resources:
          - nodehealthchecks/finalizers
          verbs:
          - update
        - apiGroups:
          - remediation.medik8s.io
          resources:
          - nodehealthchecks/status
          verbs:
          - get
          - patch
          - update
        - apiGroups:
          - authentication.k8s.io
          resources:
          - tokenreviews
          verbs:
          - create
        - apiGroups:
          - authorization.k8s.io
          resources:
          - subjectaccessreviews
          verbs:
          - create
        serviceAccountName: node-healthcheck-controller-manager
      deployments:
      - label:
          app.kubernetes.io/component: controller-manager
          app.kubernetes.io/name: node-healthcheck-operator
        name: node-healthcheck-controller-manager
        spec:
          replicas: 1
          selector:
            matchLabels:
              app.kubernetes.io/component: controller-manager
              app.kubernetes.io/name: node-healthcheck-operator
          strategy: {}
          template:
            metadata:
              annotations:
                kubectl.kubernetes.io/default-container: manager
              labels:
                app.kubernetes.io/component: controller-manager
                app.kubernetes.io/name: node-healthcheck-operator
            spec:
              affinity:
                nodeAffinity:
                  requiredDuringSchedulingIgnoredDuringExecution:
                    nodeSelectorTerms:
                    - matchExpressions:
                      - key: node-role.kubernetes.io/master
                        operator: Exists
                    - matchExpressions:
                      - key: node-role.kubernetes.io/control-plane
                        operator: Exists
              containers:
              - args:
                - --secure-listen-address=0.0.0.0:8443
                - --upstream=http://127.0.0.1:8080/
                - --logtostderr=true
                - --v=10
                image: gcr.io/kubebuilder/kube-rbac-proxy:v0.13.0
                name: kube-rbac-proxy
                ports:
                - containerPort: 8443
                  name: https
                resources: {}
                securityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop:
                    - ALL
              - args:
                - --health-probe-bind-address=:8081
                - --metrics-bind-address=127.0.0.1:8080
                - --leader-elect
                command:
                - /manager
                env:
                - name: DEPLOYMENT_NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.namespace
                image: quay.io/medik8s/node-healthcheck-operator:latest
                livenessProbe:
                  httpGet:
                    path: /healthz
                    port: 8081
                  initialDelaySeconds: 15
                  periodSeconds: 20
                name: manager
                readinessProbe:
                  httpGet:
                    path: /readyz
                    port: 8081
                  initialDelaySeconds: 5
                  periodSeconds: 10
                resources:
                  requests:
                    cpu: 100m
                    memory: 20Mi
                securityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop:
                    - ALL
              priorityClassName: system-cluster-critical
              serviceAccountName: node-healthcheck-controller-manager
              terminationGracePeriodSeconds: 10
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/master
              - effect: NoSchedule
                key: node-role.kubernetes.io/control-plane
                operator: Exists
      - label:
          app.kubernetes.io/component: node-remediation-console-plugin
          app.kubernetes.io/name: node-healthcheck-operator
        name: node-healthcheck-node-remediation-console-plugin
        spec:
          replicas: 1
          selector:
            matchLabels:
              app.kubernetes.io/component: node-remediation-console-plugin
              app.kubernetes.io/name: node-healthcheck-operator
          strategy: {}
          template:
            metadata:
              labels:
                app.kubernetes.io/component: node-remediation-console-plugin
                app.kubernetes.io/name: node-healthcheck-operator
            spec:
              containers:
              - image: quay.io/medik8s/node-remediation-console:latest
                name: node-remediation-console-plugin
                ports:
                - containerPort: 9443
                  name: nrc-server
                  protocol: TCP
                resources:
                  requests:
                    cpu: 10m
                    memory: 50Mi
                securityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop:
                    - ALL
                volumeMounts:
                - mountPath: /var/serving-cert
                  name: nrc-plugin-cert
                  readOnly: true
              securityContext:
                runAsNonRoot: true
              volumes:
              - name: nrc-plugin-cert
                secret:
                  defaultMode: 420
                  secretName: nrc-plugin-cert
      permissions:
      - rules:
        - apiGroups:
          - ""
          resources:
          - configmaps
          verbs:
          - get
          - list
          - watch
          - create
          - update
          - patch
          - delete
        - apiGroups:
          - coordination.k8s.io
          resources:
          - leases
          verbs:
          - get
          - list
          - watch
          - create
          - update
          - patch
          - delete
        - apiGroups:
          - ""
          resources:
          - events
          verbs:
          - create
          - patch
        serviceAccountName: node-healthcheck-controller-manager
    strategy: deployment
  installModes:
  - supported: false
    type: OwnNamespace
  - supported: false
    type: SingleNamespace
  - supported: false
    type: MultiNamespace
  - supported: true
    type: AllNamespaces
  keywords:
  - NHC
  - Self Node Remediation
  - SNR
  - Remediation
  - Fencing
  - medik8s
  - k8s
  links:
  - name: Node Healthcheck Operator
    url: https://medik8s.io
  - name: Source Code
    url: https://github.com/medik8s/node-healthcheck-operator
  maintainers:
  - email: medik8s@googlegroups.com
    name: Medik8s Team
  maturity: alpha
  minKubeVersion: 1.20.0
  provider:
    name: Medik8s
    url: https://github.com/medik8s
  version: 0.0.1
  webhookdefinitions:
  - admissionReviewVersions:
    - v1
    containerPort: 443
    deploymentName: node-healthcheck-controller-manager
    failurePolicy: Fail
    generateName: vnodehealthcheck.kb.io
    rules:
    - apiGroups:
      - remediation.medik8s.io
      apiVersions:
      - v1alpha1
      operations:
      - UPDATE
      - DELETE
      resources:
      - nodehealthchecks
    sideEffects: None
    targetPort: 9443
    type: ValidatingAdmissionWebhook
    webhookPath: /validate-remediation-medik8s-io-v1alpha1-nodehealthcheck
